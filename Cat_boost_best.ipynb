{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf8fab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예전 버전 코드 -> cat_boost로 단일 학습 시켜야 겠다고 마음 먹음 \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')  # 불필요한 경고 무시\n",
    "\n",
    "# 데이터 전처리 (상관관계 제거 + Smart SMOTE)\n",
    "def get_preprocessed_data():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Part 1. 데이터 전처리 시작\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 데이터 로드\n",
    "    data_splits = [\"train\", \"test\"]\n",
    "    data_categories = {\n",
    "        \"회원정보\": {\"folder\": \"1.회원정보\", \"suffix\": \"회원정보\", \"var_prefix\": \"customer\"},\n",
    "        \"신용정보\": {\"folder\": \"2.신용정보\", \"suffix\": \"신용정보\", \"var_prefix\": \"credit\"},\n",
    "        \"승인매출정보\": {\"folder\": \"3.승인매출정보\", \"suffix\": \"승인매출정보\", \"var_prefix\": \"sales\"},\n",
    "        \"청구정보\": {\"folder\": \"4.청구입금정보\", \"suffix\": \"청구정보\", \"var_prefix\": \"billing\"},\n",
    "        \"잔액정보\": {\"folder\": \"5.잔액정보\", \"suffix\": \"잔액정보\", \"var_prefix\": \"balance\"},\n",
    "        \"채널정보\": {\"folder\": \"6.채널정보\", \"suffix\": \"채널정보\", \"var_prefix\": \"channel\"},\n",
    "        \"마케팅정보\": {\"folder\": \"7.마케팅정보\", \"suffix\": \"마케팅정보\", \"var_prefix\": \"marketing\"},\n",
    "        \"성과정보\": {\"folder\": \"8.성과정보\", \"suffix\": \"성과정보\", \"var_prefix\": \"performance\"}\n",
    "    }\n",
    "\n",
    "    print(\"데이터를 불러오는 중...\")\n",
    "    raw_data = {}\n",
    "    for split in data_splits:\n",
    "        for category, info in data_categories.items():\n",
    "            file_path = f\"./data/{info['folder']}/{split}_{info['suffix']}.parquet\"\n",
    "            key = f\"{info['var_prefix']}_{split}\"\n",
    "            raw_data[key] = pd.read_parquet(file_path, engine=\"pyarrow\")\n",
    "    gc.collect()\n",
    "\n",
    "    # 데이터 병합\n",
    "    def merge_split_data(split_name, data_dict):\n",
    "        categories = [\"customer\", \"credit\", \"sales\", \"billing\", \"balance\", \"channel\", \"marketing\", \"performance\"]\n",
    "        dfs = []\n",
    "        for prefix in categories:\n",
    "            df = data_dict[f\"{prefix}_{split_name}\"]\n",
    "            if '기준년월' in df.columns and '기준년월' != 'ID':\n",
    "                df = df.drop(columns=['기준년월'])\n",
    "            dfs.append(df)\n",
    "        return reduce(lambda left, right: pd.merge(left, right, on='ID', how='left'), dfs)\n",
    "\n",
    "    merged_train_df = merge_split_data(\"train\", raw_data)\n",
    "    merged_test_df = merge_split_data(\"test\", raw_data)\n",
    "    del raw_data\n",
    "    gc.collect()\n",
    "\n",
    "    # 기본 전처리\n",
    "    target_col = 'Segment'\n",
    "    id_col = 'ID'\n",
    "    y = merged_train_df[target_col]\n",
    "    train_len = len(merged_train_df)\n",
    "    test_ids = merged_test_df[id_col]\n",
    "\n",
    "    df_all = pd.concat([merged_train_df.drop(columns=[target_col], errors='ignore'), merged_test_df], axis=0).reset_index(drop=True)\n",
    "    features_df = df_all.drop(columns=[id_col, 'customer_id'], errors='ignore')\n",
    "    features_df.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in features_df.columns]\n",
    "\n",
    "    # 변수 타입 구분\n",
    "    cat_features = []\n",
    "    num_features = []\n",
    "    for col in features_df.columns:\n",
    "        if features_df[col].dtype == 'object' or features_df[col].nunique() < 30:\n",
    "            cat_features.append(col)\n",
    "        else:\n",
    "            num_features.append(col)\n",
    "\n",
    "    X_all = features_df.copy()\n",
    "    X_all[num_features] = X_all[num_features].fillna(0)\n",
    "    X_all[cat_features] = X_all[cat_features].fillna('Missing')\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    for col in cat_features:\n",
    "        X_all[col] = le.fit_transform(X_all[col].astype(str))\n",
    "\n",
    "    # 상관관계 높은 변수 제거\n",
    "    X_temp_train = X_all.iloc[:train_len, :]\n",
    "    THRESHOLD = 0.90\n",
    "    corr_matrix = X_temp_train[num_features].corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [col for col in upper.columns if any(upper[col] > THRESHOLD)]\n",
    "    if to_drop:\n",
    "        print(f\"상관관계 {THRESHOLD} 이상 변수 {len(to_drop)}개 제거\")\n",
    "        X_all = X_all.drop(columns=to_drop, errors='ignore')\n",
    "\n",
    "    # train/test 나누기\n",
    "    X_train_final = X_all.iloc[:train_len, :]\n",
    "    X_test_final = X_all.iloc[train_len:, :]\n",
    "\n",
    "    le_y = LabelEncoder()\n",
    "    y_encoded = le_y.fit_transform(y)\n",
    "\n",
    "    # SMOTE 적용\n",
    "    print(\"학습/검증 분할 및 SMOTE 적용 중...\")\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_train_final, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
    "\n",
    "    try:\n",
    "        idx_A = list(le_y.classes_).index('A')\n",
    "        idx_B = list(le_y.classes_).index('B')\n",
    "    except ValueError:\n",
    "        idx_A, idx_B = 0, 1\n",
    "\n",
    "    smote = SMOTE(random_state=42, k_neighbors=2, sampling_strategy={idx_A: 15000, idx_B: 15000})\n",
    "    X_tr_resampled, y_tr_resampled = smote.fit_resample(X_tr, y_tr)\n",
    "\n",
    "    if not isinstance(X_tr_resampled, pd.DataFrame):\n",
    "        X_tr_resampled = pd.DataFrame(X_tr_resampled, columns=X_tr.columns)\n",
    "\n",
    "    final_cat_cols = [col for col in cat_features if col in X_tr_resampled.columns]\n",
    "    for col in final_cat_cols:\n",
    "        X_tr_resampled[col] = X_tr_resampled[col].round().astype(int)\n",
    "        X_val[col] = X_val[col].astype(int)\n",
    "        X_test_final[col] = X_test_final[col].astype(int)\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X_tr_resampled,\n",
    "        \"y_train\": y_tr_resampled,\n",
    "        \"X_val\": X_val,\n",
    "        \"y_val\": y_val,\n",
    "        \"X_test\": X_test_final,\n",
    "        \"le_y\": le_y,\n",
    "        \"test_ids\": test_ids,\n",
    "        \"cat_cols\": final_cat_cols\n",
    "    }\n",
    "\n",
    "# 모델 비교 (XGBoost, LightGBM, CatBoost)\n",
    "def run_model_comparison(data):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Part 2. 모델 비교 및 평가 시작\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    X_tr, y_tr = data[\"X_train\"], data[\"y_train\"]\n",
    "    X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "    X_test = data[\"X_test\"]\n",
    "    cat_cols = data[\"cat_cols\"]\n",
    "    le_y = data[\"le_y\"]\n",
    "\n",
    "    models = {\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            n_estimators=1000, learning_rate=0.05, max_depth=6,\n",
    "            early_stopping_rounds=50, n_jobs=-1, random_state=42,\n",
    "            enable_categorical=True, device=\"cuda\", tree_method=\"hist\"\n",
    "        ),\n",
    "        \"LightGBM\": LGBMClassifier(\n",
    "            n_estimators=1000, learning_rate=0.05, max_depth=6,\n",
    "            num_leaves=31, n_jobs=-1, random_state=42, verbose=-1\n",
    "        ),\n",
    "        \"CatBoost\": CatBoostClassifier(\n",
    "            iterations=1000, learning_rate=0.05, depth=6,\n",
    "            early_stopping_rounds=50, verbose=100, random_state=42,\n",
    "            allow_writing_files=False, cat_features=cat_cols,\n",
    "            task_type=\"GPU\", devices='0'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    best_f1 = -1\n",
    "    best_model_name = \"\"\n",
    "    best_model = None\n",
    "    results = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{name} 모델 학습 중...\")\n",
    "\n",
    "        if name == \"LightGBM\":\n",
    "            from lightgbm import early_stopping, log_evaluation\n",
    "            model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], eval_metric='multi_logloss',\n",
    "                      callbacks=[early_stopping(50), log_evaluation(0)])\n",
    "        elif name == \"CatBoost\":\n",
    "            model.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
    "        else:\n",
    "            model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=0)\n",
    "\n",
    "        val_pred = model.predict(X_val)\n",
    "        if name == \"CatBoost\":\n",
    "            val_pred = val_pred.flatten()\n",
    "\n",
    "        f1 = f1_score(y_val, val_pred, average='macro')\n",
    "        acc = accuracy_score(y_val, val_pred)\n",
    "        results.append([name, acc, f1])\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_model_name = name\n",
    "            best_model = model\n",
    "\n",
    "        print(f\"{name} 결과 - F1: {f1:.4f}, Accuracy: {acc:.4f}\")\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, val_pred))\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"모델별 성능 요약:\\n\")\n",
    "    print(pd.DataFrame(results, columns=['Model', 'Accuracy', 'Macro F1']))\n",
    "    print(f\"\\n최고 성능 모델: {best_model_name} (F1: {best_f1:.4f})\")\n",
    "\n",
    "    # 테스트 예측 및 제출 파일 저장\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    if best_model_name == \"CatBoost\":\n",
    "        test_pred = test_pred.flatten()\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': data[\"test_ids\"],\n",
    "        'Segment': le_y.inverse_transform(test_pred.astype(int))\n",
    "    })\n",
    "\n",
    "    filename = f\"submission_Final_Best_{best_model_name}_f1_{best_f1:.4f}.csv\"\n",
    "    submission.to_csv(filename, index=False)\n",
    "    print(f\"제출 파일 저장 완료: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f0ed0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_preprocessed_data():\n",
    "    print(\"데이터 전처리 시작\")\n",
    "\n",
    "    # 1. 데이터 불러오기\n",
    "    data_splits = [\"train\", \"test\"]\n",
    "    data_categories = {\n",
    "        \"회원정보\": {\"folder\": \"1.회원정보\", \"suffix\": \"회원정보\", \"var_prefix\": \"customer\"},\n",
    "        \"신용정보\": {\"folder\": \"2.신용정보\", \"suffix\": \"신용정보\", \"var_prefix\": \"credit\"},\n",
    "        \"승인매출정보\": {\"folder\": \"3.승인매출정보\", \"suffix\": \"승인매출정보\", \"var_prefix\": \"sales\"},\n",
    "        \"청구정보\": {\"folder\": \"4.청구입금정보\", \"suffix\": \"청구정보\", \"var_prefix\": \"billing\"},\n",
    "        \"잔액정보\": {\"folder\": \"5.잔액정보\", \"suffix\": \"잔액정보\", \"var_prefix\": \"balance\"},\n",
    "        \"채널정보\": {\"folder\": \"6.채널정보\", \"suffix\": \"채널정보\", \"var_prefix\": \"channel\"},\n",
    "        \"마케팅정보\": {\"folder\": \"7.마케팅정보\", \"suffix\": \"마케팅정보\", \"var_prefix\": \"marketing\"},\n",
    "        \"성과정보\": {\"folder\": \"8.성과정보\", \"suffix\": \"성과정보\", \"var_prefix\": \"performance\"}\n",
    "    }\n",
    "\n",
    "    print(\"데이터 불러오는 중...\")\n",
    "    raw_data = {}\n",
    "    for split in data_splits:\n",
    "        for category, info in data_categories.items():\n",
    "            file_path = f\"./data/{info['folder']}/{split}_{info['suffix']}.parquet\"\n",
    "            key = f\"{info['var_prefix']}_{split}\"\n",
    "            raw_data[key] = pd.read_parquet(file_path, engine=\"pyarrow\")\n",
    "    gc.collect()\n",
    "\n",
    "    # 2. 데이터 병합\n",
    "    def merge_split_data(split_name, data_dict):\n",
    "        info_categories = [\"customer\", \"credit\", \"sales\", \"billing\", \"balance\", \"channel\", \"marketing\", \"performance\"]\n",
    "        dfs_list = []\n",
    "        for prefix in info_categories:\n",
    "            df = data_dict[f\"{prefix}_{split_name}\"]\n",
    "            if '기준년월' in df.columns and '기준년월' != 'ID':\n",
    "                df = df.drop(columns=['기준년월'])\n",
    "            dfs_list.append(df)\n",
    "        return reduce(lambda left, right: pd.merge(left, right, on='ID', how='left'), dfs_list)\n",
    "\n",
    "    merged_train_df = merge_split_data(\"train\", raw_data)\n",
    "    merged_test_df = merge_split_data(\"test\", raw_data)\n",
    "    del raw_data\n",
    "    gc.collect()\n",
    "\n",
    "    # 3. 전처리\n",
    "    target_col = 'Segment'\n",
    "    id_col = 'ID'\n",
    "    y = merged_train_df[target_col]\n",
    "    train_len = len(merged_train_df)\n",
    "    test_ids = merged_test_df[id_col]\n",
    "\n",
    "    # 학습+테스트 합쳐서 전처리\n",
    "    df_all = pd.concat([merged_train_df.drop(columns=[target_col], errors='ignore'), merged_test_df], axis=0).reset_index(drop=True)\n",
    "    features_df = df_all.drop(columns=[id_col, 'customer_id'], errors='ignore')\n",
    "    features_df.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in features_df.columns]\n",
    "\n",
    "    # 수치/범주형 구분\n",
    "    Discrimination_criteria = 30\n",
    "    target_cat_features = []\n",
    "    target_num_features = []\n",
    "    for col in features_df.columns:\n",
    "        if features_df[col].dtype == 'object' or features_df[col].nunique() < Discrimination_criteria:\n",
    "            target_cat_features.append(col)\n",
    "        else:\n",
    "            target_num_features.append(col)\n",
    "\n",
    "    X_all = features_df.copy()\n",
    "\n",
    "    # 수치형 결측값 0으로 채움\n",
    "    X_all[target_num_features] = X_all[target_num_features].fillna(0)\n",
    "\n",
    "    # 범주형 결측값 처리 + 라벨 인코딩\n",
    "    X_all[target_cat_features] = X_all[target_cat_features].fillna('Missing')\n",
    "    le = LabelEncoder()\n",
    "    for col in target_cat_features:\n",
    "        X_all[col] = X_all[col].astype(str)\n",
    "        X_all[col] = le.fit_transform(X_all[col])\n",
    "\n",
    "    # 다중공선성 제거\n",
    "    X_temp_train = X_all.iloc[:train_len, :]\n",
    "    THRESHOLD = 0.94\n",
    "    current_num = [f for f in target_num_features if f in X_temp_train.columns]\n",
    "\n",
    "    to_drop = []\n",
    "    if current_num:\n",
    "        corr_matrix = X_temp_train[current_num].corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > THRESHOLD)]\n",
    "\n",
    "        if to_drop:\n",
    "            print(f\"상관 높은 컬럼 {len(to_drop)}개 제거\")\n",
    "            X_all = X_all.drop(columns=to_drop, errors='ignore')\n",
    "            target_num_features = [f for f in target_num_features if f not in to_drop]\n",
    "\n",
    "    # train / test 분리\n",
    "    X_train_final = X_all.iloc[:train_len, :]\n",
    "    X_test_final = X_all.iloc[train_len:, :]\n",
    "\n",
    "    # 타겟 인코딩\n",
    "    le_y = LabelEncoder()\n",
    "    y_encoded = le_y.fit_transform(y)\n",
    "\n",
    "    print(f\"전처리 완료됨. 학습 데이터 shape: {X_train_final.shape}\")\n",
    "\n",
    "    # 4. 학습/검증 분할 + SMOTE\n",
    "    print(\"학습/검증 세트로 나누는 중...\")\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train_final, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"SMOTE 전 클래스 분포: {np.bincount(y_tr)}\")\n",
    "\n",
    "    try:\n",
    "        idx_A = list(le_y.classes_).index('A')\n",
    "        idx_B = list(le_y.classes_).index('B')\n",
    "    except ValueError:\n",
    "        print(\"클래스 'A', 'B' 없음. 기본 index로 진행\")\n",
    "        idx_A, idx_B = 0, 1\n",
    "\n",
    "    smote_strategy = {\n",
    "        idx_A: 15000, \n",
    "        idx_B: 15000\n",
    "    }\n",
    "\n",
    "    print(\"SMOTE 적용 중...\")\n",
    "    smote = SMOTE(random_state=42, k_neighbors=2, sampling_strategy=smote_strategy)\n",
    "    X_tr_resampled, y_tr_resampled = smote.fit_resample(X_tr, y_tr)\n",
    "\n",
    "    if not isinstance(X_tr_resampled, pd.DataFrame):\n",
    "        X_tr_resampled = pd.DataFrame(X_tr_resampled, columns=X_tr.columns)\n",
    "\n",
    "    # 범주형 다시 정수로 보정\n",
    "    final_cat_cols = [c for c in target_cat_features if c in X_tr_resampled.columns]\n",
    "    for col in final_cat_cols:\n",
    "        X_tr_resampled[col] = X_tr_resampled[col].round().astype(int)\n",
    "        X_val[col] = X_val[col].astype(int)\n",
    "        X_test_final[col] = X_test_final[col].astype(int)\n",
    "\n",
    "    print(f\"SMOTE 후 클래스 분포: {np.bincount(y_tr_resampled)}\")\n",
    "    print(f\"학습 샘플 수: {len(y_tr)} → {len(y_tr_resampled)}\")\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X_tr_resampled,\n",
    "        \"y_train\": y_tr_resampled,\n",
    "        \"X_val\": X_val,\n",
    "        \"y_val\": y_val,\n",
    "        \"X_test\": X_test_final,\n",
    "        \"le_y\": le_y,\n",
    "        \"test_ids\": test_ids,\n",
    "        \"cat_cols\": final_cat_cols\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09d0993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def run_model_Cat_boost_comparison(data):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CatBoost 최적 파라미터로 모델 학습 시작\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    X_tr, y_tr = data[\"X_train\"], data[\"y_train\"]\n",
    "    X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "    X_test = data[\"X_test\"]\n",
    "    cat_cols = data[\"cat_cols\"]\n",
    "    le_y = data[\"le_y\"]\n",
    "\n",
    "    # Optuna로 튜닝된 최종 파라미터 사용\n",
    "    models = {\n",
    "        \"CatBoost\": CatBoostClassifier(\n",
    "            iterations=1500,\n",
    "            depth=5,\n",
    "            learning_rate=0.04268265981566772,\n",
    "            l2_leaf_reg=3,\n",
    "            random_strength=3.394598804716689e-07,\n",
    "            bagging_temperature=0.7017937881211938,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=100,\n",
    "            random_state=42,\n",
    "            allow_writing_files=False,\n",
    "            cat_features=cat_cols,\n",
    "            task_type=\"GPU\",\n",
    "            devices='0'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    best_f1 = -1\n",
    "    best_model_name = \"\"\n",
    "    best_model = None\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(\"\\n\" + \"-\"*40)\n",
    "        print(f\"{name} 모델 학습 중...\")\n",
    "        print(\"-\"*40)\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
    "\n",
    "        # 검증 평가\n",
    "        val_pred = model.predict(X_val).flatten()\n",
    "        f1 = f1_score(y_val, val_pred, average='macro')\n",
    "        acc = accuracy_score(y_val, val_pred)\n",
    "        results.append([name, acc, f1])\n",
    "\n",
    "        best_f1 = f1\n",
    "        best_model_name = name\n",
    "        best_model = model\n",
    "\n",
    "        # 리포트 출력\n",
    "        print(f\"\\n{name} 결과 요약:\")\n",
    "        print(f\"Macro F1: {f1:.4f}, Accuracy: {acc:.4f}\")\n",
    "        print(classification_report(y_val, val_pred, target_names=le_y.classes_))\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_val, val_pred))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"최종 모델: {best_model_name} / F1 점수: {best_f1:.4f}\")\n",
    "\n",
    "    # 예측 및 제출 파일 생성\n",
    "    print(\"테스트 데이터 예측 및 제출 파일 생성\")\n",
    "    test_pred = best_model.predict(X_test).flatten()\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': data[\"test_ids\"],\n",
    "        'Segment': le_y.inverse_transform(test_pred.astype(int))\n",
    "    })\n",
    "\n",
    "    filename = f\"submission_Final_CatBoost_Optuna_f1_{best_f1:.4f}.csv\"\n",
    "    submission.to_csv(filename, index=False)\n",
    "    print(f\"제출 파일 저장 완료: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2a6fa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 전처리 시작\n",
      "데이터 불러오는 중...\n",
      "상관 높은 컬럼 140개 제거\n",
      "전처리 완료됨. 학습 데이터 shape: (400000, 715)\n",
      "학습/검증 세트로 나누는 중...\n",
      "SMOTE 전 클래스 분포: [   130     19  17012  46565 256274]\n",
      "SMOTE 적용 중...\n",
      "SMOTE 후 클래스 분포: [ 15000  15000  17012  46565 256274]\n",
      "학습 샘플 수: 320000 → 349851\n"
     ]
    }
   ],
   "source": [
    "# 1. 전처리 실행 (데이터 준비)\n",
    "data_pack = get_preprocessed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95a1c9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CatBoost 최적 파라미터로 모델 학습 시작\n",
      "============================================================\n",
      "\n",
      "----------------------------------------\n",
      "CatBoost 모델 학습 중...\n",
      "----------------------------------------\n",
      "0:\tlearn: 1.4911611\ttest: 1.4910142\tbest: 1.4910142 (0)\ttotal: 33.5ms\tremaining: 50.2s\n",
      "100:\tlearn: 0.3344999\ttest: 0.3485464\tbest: 0.3485464 (100)\ttotal: 2.66s\tremaining: 36.9s\n",
      "200:\tlearn: 0.2906516\ttest: 0.3115905\tbest: 0.3115905 (200)\ttotal: 5.65s\tremaining: 36.5s\n",
      "300:\tlearn: 0.2733539\ttest: 0.2964569\tbest: 0.2964569 (300)\ttotal: 8.4s\tremaining: 33.5s\n",
      "400:\tlearn: 0.2624542\ttest: 0.2868684\tbest: 0.2868684 (400)\ttotal: 10.8s\tremaining: 29.5s\n",
      "500:\tlearn: 0.2551233\ttest: 0.2804574\tbest: 0.2804574 (500)\ttotal: 13s\tremaining: 25.9s\n",
      "600:\tlearn: 0.2491296\ttest: 0.2752422\tbest: 0.2752422 (600)\ttotal: 15.2s\tremaining: 22.7s\n",
      "700:\tlearn: 0.2445749\ttest: 0.2714514\tbest: 0.2714514 (700)\ttotal: 17.4s\tremaining: 19.8s\n",
      "800:\tlearn: 0.2407784\ttest: 0.2684652\tbest: 0.2684652 (800)\ttotal: 19.7s\tremaining: 17.2s\n",
      "900:\tlearn: 0.2375025\ttest: 0.2659822\tbest: 0.2659822 (900)\ttotal: 21.9s\tremaining: 14.6s\n",
      "1000:\tlearn: 0.2348910\ttest: 0.2640684\tbest: 0.2640684 (1000)\ttotal: 24s\tremaining: 12s\n",
      "1100:\tlearn: 0.2324034\ttest: 0.2622368\tbest: 0.2622368 (1100)\ttotal: 26.2s\tremaining: 9.48s\n",
      "1200:\tlearn: 0.2304284\ttest: 0.2608676\tbest: 0.2608676 (1200)\ttotal: 29s\tremaining: 7.22s\n",
      "1300:\tlearn: 0.2285666\ttest: 0.2595664\tbest: 0.2595664 (1300)\ttotal: 31.4s\tremaining: 4.79s\n",
      "1400:\tlearn: 0.2268648\ttest: 0.2584575\tbest: 0.2584575 (1400)\ttotal: 34.2s\tremaining: 2.41s\n",
      "1499:\tlearn: 0.2254205\ttest: 0.2575753\tbest: 0.2575753 (1499)\ttotal: 36.9s\tremaining: 0us\n",
      "bestTest = 0.257575293\n",
      "bestIteration = 1499\n",
      "\n",
      "CatBoost 결과 요약:\n",
      "Macro F1: 0.5922, Accuracy: 0.8972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.25      0.66      0.37        32\n",
      "           B       1.00      0.20      0.33         5\n",
      "           C       0.73      0.59      0.65      4253\n",
      "           D       0.70      0.62      0.66     11642\n",
      "           E       0.94      0.97      0.95     64068\n",
      "\n",
      "    accuracy                           0.90     80000\n",
      "   macro avg       0.72      0.61      0.59     80000\n",
      "weighted avg       0.89      0.90      0.89     80000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   21     0    11     0     0]\n",
      " [    1     1     3     0     0]\n",
      " [   52     0  2505  1266   430]\n",
      " [    6     0   722  7209  3705]\n",
      " [    3     0   170  1853 62042]]\n",
      "\n",
      "============================================================\n",
      "최종 모델: CatBoost / F1 점수: 0.5922\n",
      "테스트 데이터 예측 및 제출 파일 생성\n",
      "제출 파일 저장 완료: submission_Final_CatBoost_Optuna_f1_0.5922.csv\n"
     ]
    }
   ],
   "source": [
    "run_model_Cat_boost_comparison(data_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47427ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_Cat_boost_comparison(data):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CatBoost 최적 파라미터로 학습 시작\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    X_tr, y_tr = data[\"X_train\"], data[\"y_train\"]\n",
    "    X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "    X_test = data[\"X_test\"]\n",
    "    cat_cols = data[\"cat_cols\"]\n",
    "    le_y = data[\"le_y\"]\n",
    "\n",
    "    # Optuna로 튜닝된 파라미터 사용\n",
    "    models = {\n",
    "        \"CatBoost\": CatBoostClassifier(\n",
    "            iterations=1500,\n",
    "            depth=5,\n",
    "            learning_rate=0.04268265981566772,\n",
    "            l2_leaf_reg=3,\n",
    "            random_strength=3.394598804716689e-07,\n",
    "            bagging_temperature=0.7017937881211938,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=100,\n",
    "            random_state=42,\n",
    "            allow_writing_files=False,\n",
    "            cat_features=cat_cols,\n",
    "            task_type=\"GPU\",\n",
    "            devices='0'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(\"\\n\" + \"-\"*40)\n",
    "        print(f\"{name} 모델 학습 중...\")\n",
    "        print(\"-\"*40)\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
    "        best_model = model\n",
    "\n",
    "    print(\"모델 학습 완료. 객체 반환\")\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "775a8e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CatBoost 최적 파라미터로 학습 시작\n",
      "============================================================\n",
      "\n",
      "----------------------------------------\n",
      "CatBoost 모델 학습 중...\n",
      "----------------------------------------\n",
      "0:\tlearn: 1.4911611\ttest: 1.4910138\tbest: 1.4910138 (0)\ttotal: 247ms\tremaining: 6m 9s\n",
      "100:\tlearn: 0.3344999\ttest: 0.3485465\tbest: 0.3485465 (100)\ttotal: 2.17s\tremaining: 30.1s\n",
      "200:\tlearn: 0.2906515\ttest: 0.3115907\tbest: 0.3115907 (200)\ttotal: 4.21s\tremaining: 27.2s\n",
      "300:\tlearn: 0.2733539\ttest: 0.2964570\tbest: 0.2964570 (300)\ttotal: 6.25s\tremaining: 24.9s\n",
      "400:\tlearn: 0.2624542\ttest: 0.2868683\tbest: 0.2868683 (400)\ttotal: 8.2s\tremaining: 22.5s\n",
      "500:\tlearn: 0.2551233\ttest: 0.2804574\tbest: 0.2804574 (500)\ttotal: 10.1s\tremaining: 20.2s\n",
      "600:\tlearn: 0.2491297\ttest: 0.2752422\tbest: 0.2752422 (600)\ttotal: 12s\tremaining: 18s\n",
      "700:\tlearn: 0.2445748\ttest: 0.2714515\tbest: 0.2714515 (700)\ttotal: 13.9s\tremaining: 15.8s\n",
      "800:\tlearn: 0.2407783\ttest: 0.2684652\tbest: 0.2684652 (800)\ttotal: 15.7s\tremaining: 13.7s\n",
      "900:\tlearn: 0.2375026\ttest: 0.2659823\tbest: 0.2659823 (900)\ttotal: 17.5s\tremaining: 11.6s\n",
      "1000:\tlearn: 0.2348910\ttest: 0.2640684\tbest: 0.2640684 (1000)\ttotal: 19.3s\tremaining: 9.6s\n",
      "1100:\tlearn: 0.2324034\ttest: 0.2622369\tbest: 0.2622369 (1100)\ttotal: 21s\tremaining: 7.61s\n",
      "1200:\tlearn: 0.2304285\ttest: 0.2608675\tbest: 0.2608675 (1200)\ttotal: 22.8s\tremaining: 5.68s\n",
      "1300:\tlearn: 0.2285569\ttest: 0.2595594\tbest: 0.2595594 (1300)\ttotal: 24.6s\tremaining: 3.76s\n",
      "1400:\tlearn: 0.2268740\ttest: 0.2584394\tbest: 0.2584394 (1400)\ttotal: 26.2s\tremaining: 1.85s\n",
      "1499:\tlearn: 0.2253636\ttest: 0.2574380\tbest: 0.2574380 (1499)\ttotal: 27.9s\tremaining: 0us\n",
      "bestTest = 0.2574380127\n",
      "bestIteration = 1499\n",
      "모델 학습 완료. 객체 반환\n"
     ]
    }
   ],
   "source": [
    "model = run_model_Cat_boost_comparison(data_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca53f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "검증 데이터로 모델 성능 평가함\n",
      "==================================================\n",
      "Macro F1: 0.5933, Accuracy: 0.8975\n",
      "--------------------------------------------------\n",
      "분류 리포트:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.26      0.66      0.37        32\n",
      "           B       1.00      0.20      0.33         5\n",
      "           C       0.74      0.59      0.65      4253\n",
      "           D       0.70      0.62      0.66     11642\n",
      "           E       0.94      0.97      0.95     64068\n",
      "\n",
      "    accuracy                           0.90     80000\n",
      "   macro avg       0.73      0.61      0.59     80000\n",
      "weighted avg       0.89      0.90      0.89     80000\n",
      "\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "\n",
      "[[   21     0    11     0     0]\n",
      " [    1     1     3     0     0]\n",
      " [   51     0  2508  1262   432]\n",
      " [    6     0   717  7226  3693]\n",
      " [    3     0   171  1849 62045]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "# 학습된 모델 성능 평가\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"검증 데이터로 모델 성능 평가함\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 예측 수행\n",
    "val_pred = model.predict(data_pack[\"X_val\"]).flatten()\n",
    "\n",
    "# 점수 계산\n",
    "f1 = f1_score(data_pack[\"y_val\"], val_pred, average='macro')\n",
    "acc = accuracy_score(data_pack[\"y_val\"], val_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Macro F1: {f1:.4f}, Accuracy: {acc:.4f}\")\n",
    "print(\"-\" * 50)\n",
    "print(\"분류 리포트:\\n\")\n",
    "print(classification_report(data_pack[\"y_val\"], val_pred, target_names=data_pack[\"le_y\"].classes_))\n",
    "print(\"-\" * 50)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(data_pack[\"y_val\"], val_pred))\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
