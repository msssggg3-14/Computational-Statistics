{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f0ed0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "# ê²½ê³  ë¬´ì‹œ\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_preprocessed_data():\n",
    "    print(\"ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘\")\n",
    "\n",
    "    # 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    data_splits = [\"train\", \"test\"]\n",
    "    data_categories = {\n",
    "        \"íšŒì›ì •ë³´\": {\"folder\": \"1.íšŒì›ì •ë³´\", \"suffix\": \"íšŒì›ì •ë³´\", \"var_prefix\": \"customer\"},\n",
    "        \"ì‹ ìš©ì •ë³´\": {\"folder\": \"2.ì‹ ìš©ì •ë³´\", \"suffix\": \"ì‹ ìš©ì •ë³´\", \"var_prefix\": \"credit\"},\n",
    "        \"ìŠ¹ì¸ë§¤ì¶œì •ë³´\": {\"folder\": \"3.ìŠ¹ì¸ë§¤ì¶œì •ë³´\", \"suffix\": \"ìŠ¹ì¸ë§¤ì¶œì •ë³´\", \"var_prefix\": \"sales\"},\n",
    "        \"ì²­êµ¬ì •ë³´\": {\"folder\": \"4.ì²­êµ¬ì…ê¸ˆì •ë³´\", \"suffix\": \"ì²­êµ¬ì •ë³´\", \"var_prefix\": \"billing\"},\n",
    "        \"ì”ì•¡ì •ë³´\": {\"folder\": \"5.ì”ì•¡ì •ë³´\", \"suffix\": \"ì”ì•¡ì •ë³´\", \"var_prefix\": \"balance\"},\n",
    "        \"ì±„ë„ì •ë³´\": {\"folder\": \"6.ì±„ë„ì •ë³´\", \"suffix\": \"ì±„ë„ì •ë³´\", \"var_prefix\": \"channel\"},\n",
    "        \"ë§ˆì¼€íŒ…ì •ë³´\": {\"folder\": \"7.ë§ˆì¼€íŒ…ì •ë³´\", \"suffix\": \"ë§ˆì¼€íŒ…ì •ë³´\", \"var_prefix\": \"marketing\"},\n",
    "        \"ì„±ê³¼ì •ë³´\": {\"folder\": \"8.ì„±ê³¼ì •ë³´\", \"suffix\": \"ì„±ê³¼ì •ë³´\", \"var_prefix\": \"performance\"}\n",
    "    }\n",
    "\n",
    "    print(\"ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\")\n",
    "    raw_data = {}\n",
    "    for split in data_splits:\n",
    "        for category, info in data_categories.items():\n",
    "            file_path = f\"./data/{info['folder']}/{split}_{info['suffix']}.parquet\"\n",
    "            key = f\"{info['var_prefix']}_{split}\"\n",
    "            raw_data[key] = pd.read_parquet(file_path, engine=\"pyarrow\")\n",
    "    gc.collect()\n",
    "\n",
    "    # 2. ë°ì´í„° ë³‘í•©\n",
    "    def merge_split_data(split_name, data_dict):\n",
    "        info_categories = [\"customer\", \"credit\", \"sales\", \"billing\", \"balance\", \"channel\", \"marketing\", \"performance\"]\n",
    "        dfs_list = []\n",
    "        for prefix in info_categories:\n",
    "            df = data_dict[f\"{prefix}_{split_name}\"]\n",
    "            if 'ê¸°ì¤€ë…„ì›”' in df.columns and 'ê¸°ì¤€ë…„ì›”' != 'ID':\n",
    "                df = df.drop(columns=['ê¸°ì¤€ë…„ì›”'])\n",
    "            dfs_list.append(df)\n",
    "        return reduce(lambda left, right: pd.merge(left, right, on='ID', how='left'), dfs_list)\n",
    "\n",
    "    merged_train_df = merge_split_data(\"train\", raw_data)\n",
    "    merged_test_df = merge_split_data(\"test\", raw_data)\n",
    "    del raw_data\n",
    "    gc.collect()\n",
    "\n",
    "    # 3. ì „ì²˜ë¦¬\n",
    "    target_col = 'Segment'\n",
    "    id_col = 'ID'\n",
    "    y = merged_train_df[target_col]\n",
    "    train_len = len(merged_train_df)\n",
    "    test_ids = merged_test_df[id_col]\n",
    "\n",
    "    # í•™ìŠµ+í…ŒìŠ¤íŠ¸ í•©ì³ì„œ ì „ì²˜ë¦¬\n",
    "    df_all = pd.concat([merged_train_df.drop(columns=[target_col], errors='ignore'), merged_test_df], axis=0).reset_index(drop=True)\n",
    "    features_df = df_all.drop(columns=[id_col, 'customer_id'], errors='ignore')\n",
    "    features_df.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in features_df.columns]\n",
    "\n",
    "    # ìˆ˜ì¹˜/ë²”ì£¼í˜• êµ¬ë¶„\n",
    "    Discrimination_criteria = 30\n",
    "    target_cat_features = []\n",
    "    target_num_features = []\n",
    "    for col in features_df.columns:\n",
    "        if features_df[col].dtype == 'object' or features_df[col].nunique() < Discrimination_criteria:\n",
    "            target_cat_features.append(col)\n",
    "        else:\n",
    "            target_num_features.append(col)\n",
    "\n",
    "    X_all = features_df.copy()\n",
    "\n",
    "    # ìˆ˜ì¹˜í˜• ê²°ì¸¡ê°’ 0ìœ¼ë¡œ ì±„ì›€\n",
    "    X_all[target_num_features] = X_all[target_num_features].fillna(0)\n",
    "\n",
    "    # ë²”ì£¼í˜• ê²°ì¸¡ê°’ ì²˜ë¦¬ + ë¼ë²¨ ì¸ì½”ë”©\n",
    "    X_all[target_cat_features] = X_all[target_cat_features].fillna('Missing')\n",
    "    le = LabelEncoder()\n",
    "    for col in target_cat_features:\n",
    "        X_all[col] = X_all[col].astype(str)\n",
    "        X_all[col] = le.fit_transform(X_all[col])\n",
    "\n",
    "    # ë‹¤ì¤‘ê³µì„ ì„± ì œê±°\n",
    "    X_temp_train = X_all.iloc[:train_len, :]\n",
    "    THRESHOLD = 0.94\n",
    "    current_num = [f for f in target_num_features if f in X_temp_train.columns]\n",
    "\n",
    "    to_drop = []\n",
    "    if current_num:\n",
    "        corr_matrix = X_temp_train[current_num].corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > THRESHOLD)]\n",
    "\n",
    "        if to_drop:\n",
    "            print(f\"ìƒê´€ ë†’ì€ ì»¬ëŸ¼ {len(to_drop)}ê°œ ì œê±°\")\n",
    "            X_all = X_all.drop(columns=to_drop, errors='ignore')\n",
    "            target_num_features = [f for f in target_num_features if f not in to_drop]\n",
    "\n",
    "    # train / test ë¶„ë¦¬\n",
    "    X_train_final = X_all.iloc[:train_len, :]\n",
    "    X_test_final = X_all.iloc[train_len:, :]\n",
    "\n",
    "    # íƒ€ê²Ÿ ì¸ì½”ë”©\n",
    "    le_y = LabelEncoder()\n",
    "    y_encoded = le_y.fit_transform(y)\n",
    "\n",
    "    print(f\"ì „ì²˜ë¦¬ ì™„ë£Œë¨. í•™ìŠµ ë°ì´í„° shape: {X_train_final.shape}\")\n",
    "\n",
    "    # 4. í•™ìŠµ/ê²€ì¦ ë¶„í•  + SMOTE\n",
    "    print(\"í•™ìŠµ/ê²€ì¦ ì„¸íŠ¸ë¡œ ë‚˜ëˆ„ëŠ” ì¤‘...\")\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train_final, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"SMOTE ì „ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_tr)}\")\n",
    "\n",
    "    try:\n",
    "        idx_A = list(le_y.classes_).index('A')\n",
    "        idx_B = list(le_y.classes_).index('B')\n",
    "    except ValueError:\n",
    "        print(\"í´ë˜ìŠ¤ 'A', 'B' ì—†ìŒ. ê¸°ë³¸ indexë¡œ ì§„í–‰\")\n",
    "        idx_A, idx_B = 0, 1\n",
    "\n",
    "    smote_strategy = {\n",
    "        idx_A: 15000, \n",
    "        idx_B: 15000\n",
    "    }\n",
    "\n",
    "    print(\"SMOTE ì ìš© ì¤‘...\")\n",
    "    smote = SMOTE(random_state=42, k_neighbors=2, sampling_strategy=smote_strategy)\n",
    "    X_tr_resampled, y_tr_resampled = smote.fit_resample(X_tr, y_tr)\n",
    "\n",
    "    if not isinstance(X_tr_resampled, pd.DataFrame):\n",
    "        X_tr_resampled = pd.DataFrame(X_tr_resampled, columns=X_tr.columns)\n",
    "\n",
    "    # ë²”ì£¼í˜• ë‹¤ì‹œ ì •ìˆ˜ë¡œ ë³´ì •\n",
    "    final_cat_cols = [c for c in target_cat_features if c in X_tr_resampled.columns]\n",
    "    for col in final_cat_cols:\n",
    "        X_tr_resampled[col] = X_tr_resampled[col].round().astype(int)\n",
    "        X_val[col] = X_val[col].astype(int)\n",
    "        X_test_final[col] = X_test_final[col].astype(int)\n",
    "\n",
    "    print(f\"SMOTE í›„ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_tr_resampled)}\")\n",
    "    print(f\"í•™ìŠµ ìƒ˜í”Œ ìˆ˜: {len(y_tr)} â†’ {len(y_tr_resampled)}\")\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X_tr_resampled,\n",
    "        \"y_train\": y_tr_resampled,\n",
    "        \"X_val\": X_val,\n",
    "        \"y_val\": y_val,\n",
    "        \"X_test\": X_test_final,\n",
    "        \"le_y\": le_y,\n",
    "        \"test_ids\": test_ids,\n",
    "        \"cat_cols\": final_cat_cols\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09d0993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def run_model_Cat_boost_comparison(data):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CatBoost ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í•™ìŠµ ì‹œì‘\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    X_tr, y_tr = data[\"X_train\"], data[\"y_train\"]\n",
    "    X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "    X_test = data[\"X_test\"]\n",
    "    cat_cols = data[\"cat_cols\"]\n",
    "    le_y = data[\"le_y\"]\n",
    "\n",
    "    # Optunaë¡œ íŠœë‹ëœ ìµœì¢… íŒŒë¼ë¯¸í„° ì‚¬ìš©\n",
    "    models = {\n",
    "        \"CatBoost\": CatBoostClassifier(\n",
    "            iterations=1500,\n",
    "            depth=5,\n",
    "            learning_rate=0.04268265981566772,\n",
    "            l2_leaf_reg=3,\n",
    "            random_strength=3.394598804716689e-07,\n",
    "            bagging_temperature=0.7017937881211938,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=100,\n",
    "            random_state=42,\n",
    "            allow_writing_files=False,\n",
    "            cat_features=cat_cols,\n",
    "            task_type=\"GPU\",\n",
    "            devices='0'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    best_f1 = -1\n",
    "    best_model_name = \"\"\n",
    "    best_model = None\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(\"\\n\" + \"-\"*40)\n",
    "        print(f\"{name} ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "        print(\"-\"*40)\n",
    "\n",
    "        # ëª¨ë¸ í•™ìŠµ\n",
    "        model.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
    "\n",
    "        # ê²€ì¦ í‰ê°€\n",
    "        val_pred = model.predict(X_val).flatten()\n",
    "        f1 = f1_score(y_val, val_pred, average='macro')\n",
    "        acc = accuracy_score(y_val, val_pred)\n",
    "        results.append([name, acc, f1])\n",
    "\n",
    "        best_f1 = f1\n",
    "        best_model_name = name\n",
    "        best_model = model\n",
    "\n",
    "        # ë¦¬í¬íŠ¸ ì¶œë ¥\n",
    "        print(f\"\\n{name} ê²°ê³¼ ìš”ì•½:\")\n",
    "        print(f\"Macro F1: {f1:.4f}, Accuracy: {acc:.4f}\")\n",
    "        print(classification_report(y_val, val_pred, target_names=le_y.classes_))\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_val, val_pred))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ìµœì¢… ëª¨ë¸: {best_model_name} / F1 ì ìˆ˜: {best_f1:.4f}\")\n",
    "\n",
    "    # ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "    print(\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±\")\n",
    "    test_pred = best_model.predict(X_test).flatten()\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': data[\"test_ids\"],\n",
    "        'Segment': le_y.inverse_transform(test_pred.astype(int))\n",
    "    })\n",
    "\n",
    "    filename = f\"submission_Final_CatBoost_Optuna_f1_{best_f1:.4f}.csv\"\n",
    "    submission.to_csv(filename, index=False)\n",
    "    print(f\"ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a6fa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘\n",
      "ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\n"
     ]
    }
   ],
   "source": [
    "# 1. ì „ì²˜ë¦¬ ì‹¤í–‰ (ë°ì´í„° ì¤€ë¹„)\n",
    "data_pack = get_preprocessed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1c9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CatBoost ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í•™ìŠµ ì‹œì‘\n",
      "============================================================\n",
      "\n",
      "----------------------------------------\n",
      "CatBoost ëª¨ë¸ í•™ìŠµ ì¤‘...\n",
      "----------------------------------------\n",
      "0:\tlearn: 1.4911615\ttest: 1.4910140\tbest: 1.4910140 (0)\ttotal: 245ms\tremaining: 6m 7s\n",
      "100:\tlearn: 0.3344999\ttest: 0.3485464\tbest: 0.3485464 (100)\ttotal: 3.28s\tremaining: 45.4s\n",
      "200:\tlearn: 0.2906515\ttest: 0.3115906\tbest: 0.3115906 (200)\ttotal: 6.27s\tremaining: 40.5s\n",
      "300:\tlearn: 0.2733540\ttest: 0.2964570\tbest: 0.2964570 (300)\ttotal: 9.5s\tremaining: 37.9s\n",
      "400:\tlearn: 0.2624541\ttest: 0.2868684\tbest: 0.2868684 (400)\ttotal: 12.5s\tremaining: 34.3s\n",
      "500:\tlearn: 0.2551231\ttest: 0.2804574\tbest: 0.2804574 (500)\ttotal: 15.3s\tremaining: 30.5s\n",
      "600:\tlearn: 0.2491297\ttest: 0.2752423\tbest: 0.2752423 (600)\ttotal: 17.9s\tremaining: 26.7s\n",
      "700:\tlearn: 0.2445748\ttest: 0.2714515\tbest: 0.2714515 (700)\ttotal: 20.5s\tremaining: 23.3s\n",
      "800:\tlearn: 0.2407783\ttest: 0.2684653\tbest: 0.2684653 (800)\ttotal: 22.9s\tremaining: 20s\n",
      "900:\tlearn: 0.2375026\ttest: 0.2659823\tbest: 0.2659823 (900)\ttotal: 25.4s\tremaining: 16.9s\n",
      "1000:\tlearn: 0.2348910\ttest: 0.2640684\tbest: 0.2640684 (1000)\ttotal: 27.7s\tremaining: 13.8s\n",
      "1100:\tlearn: 0.2324035\ttest: 0.2622367\tbest: 0.2622367 (1100)\ttotal: 30s\tremaining: 10.9s\n",
      "1200:\tlearn: 0.2304284\ttest: 0.2608676\tbest: 0.2608676 (1200)\ttotal: 32.1s\tremaining: 7.99s\n",
      "1300:\tlearn: 0.2285569\ttest: 0.2595595\tbest: 0.2595595 (1300)\ttotal: 34.4s\tremaining: 5.27s\n",
      "1400:\tlearn: 0.2268882\ttest: 0.2584362\tbest: 0.2584362 (1400)\ttotal: 36.5s\tremaining: 2.58s\n",
      "1499:\tlearn: 0.2253677\ttest: 0.2573965\tbest: 0.2573965 (1499)\ttotal: 38.8s\tremaining: 0us\n",
      "bestTest = 0.2573965088\n",
      "bestIteration = 1499\n",
      "\n",
      "CatBoost ê²°ê³¼ ìš”ì•½:\n",
      "Macro F1: 0.5922, Accuracy: 0.8976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.25      0.66      0.36        32\n",
      "           B       1.00      0.20      0.33         5\n",
      "           C       0.74      0.59      0.66      4253\n",
      "           D       0.70      0.62      0.66     11642\n",
      "           E       0.94      0.97      0.95     64068\n",
      "\n",
      "    accuracy                           0.90     80000\n",
      "   macro avg       0.72      0.61      0.59     80000\n",
      "weighted avg       0.89      0.90      0.89     80000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   21     0    11     0     0]\n",
      " [    1     1     3     0     0]\n",
      " [   53     0  2511  1260   429]\n",
      " [    6     0   721  7220  3695]\n",
      " [    3     0   168  1839 62058]]\n",
      "\n",
      "============================================================\n",
      "ìµœì¢… ëª¨ë¸: CatBoost / F1 ì ìˆ˜: 0.5922\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
      "ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: submission_Final_CatBoost_Optuna_f1_0.5922.csv\n"
     ]
    }
   ],
   "source": [
    "run_model_Cat_boost_comparison(data_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47427ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_Cat_boost_comparison(data):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CatBoost ìµœì  íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµ ì‹œì‘\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    X_tr, y_tr = data[\"X_train\"], data[\"y_train\"]\n",
    "    X_val, y_val = data[\"X_val\"], data[\"y_val\"]\n",
    "    X_test = data[\"X_test\"]\n",
    "    cat_cols = data[\"cat_cols\"]\n",
    "    le_y = data[\"le_y\"]\n",
    "\n",
    "    # Optunaë¡œ íŠœë‹ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©\n",
    "    models = {\n",
    "        \"CatBoost\": CatBoostClassifier(\n",
    "            iterations=1500,\n",
    "            depth=5,\n",
    "            learning_rate=0.04268265981566772,\n",
    "            l2_leaf_reg=3,\n",
    "            random_strength=3.394598804716689e-07,\n",
    "            bagging_temperature=0.7017937881211938,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=100,\n",
    "            random_state=42,\n",
    "            allow_writing_files=False,\n",
    "            cat_features=cat_cols,\n",
    "            task_type=\"GPU\",\n",
    "            devices='0'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(\"\\n\" + \"-\"*40)\n",
    "        print(f\"{name} ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "        print(\"-\"*40)\n",
    "\n",
    "        # ëª¨ë¸ í•™ìŠµ\n",
    "        model.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
    "        best_model = model\n",
    "\n",
    "    print(\"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ. ê°ì²´ ë°˜í™˜\")\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a8e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      ">>> [Part 2] CatBoost ìµœì  íŒŒë¼ë¯¸í„° ì ìš© í•™ìŠµ (Real Final ğŸš€)\n",
      "============================================================\n",
      "\n",
      "----------------------------------------\n",
      ">>> [CatBoost] í•™ìŠµ ì‹œì‘... (Optuna Optimized)\n",
      "----------------------------------------\n",
      "0:\tlearn: 1.4911612\ttest: 1.4910139\tbest: 1.4910139 (0)\ttotal: 209ms\tremaining: 5m 13s\n",
      "100:\tlearn: 0.3344999\ttest: 0.3485464\tbest: 0.3485464 (100)\ttotal: 2.26s\tremaining: 31.3s\n",
      "200:\tlearn: 0.2906516\ttest: 0.3115906\tbest: 0.3115906 (200)\ttotal: 4.22s\tremaining: 27.3s\n",
      "300:\tlearn: 0.2733539\ttest: 0.2964570\tbest: 0.2964570 (300)\ttotal: 6.05s\tremaining: 24.1s\n",
      "400:\tlearn: 0.2624541\ttest: 0.2868685\tbest: 0.2868685 (400)\ttotal: 8.04s\tremaining: 22s\n",
      "500:\tlearn: 0.2551232\ttest: 0.2804573\tbest: 0.2804573 (500)\ttotal: 9.99s\tremaining: 19.9s\n",
      "600:\tlearn: 0.2491297\ttest: 0.2752423\tbest: 0.2752423 (600)\ttotal: 12s\tremaining: 17.9s\n",
      "700:\tlearn: 0.2445749\ttest: 0.2714515\tbest: 0.2714515 (700)\ttotal: 13.9s\tremaining: 15.8s\n",
      "800:\tlearn: 0.2407783\ttest: 0.2684653\tbest: 0.2684653 (800)\ttotal: 15.8s\tremaining: 13.8s\n",
      "900:\tlearn: 0.2375026\ttest: 0.2659823\tbest: 0.2659823 (900)\ttotal: 17.8s\tremaining: 11.8s\n",
      "1000:\tlearn: 0.2348910\ttest: 0.2640684\tbest: 0.2640684 (1000)\ttotal: 19.7s\tremaining: 9.83s\n",
      "1100:\tlearn: 0.2324035\ttest: 0.2622367\tbest: 0.2622367 (1100)\ttotal: 21.6s\tremaining: 7.82s\n",
      "1200:\tlearn: 0.2304284\ttest: 0.2608676\tbest: 0.2608676 (1200)\ttotal: 23.3s\tremaining: 5.81s\n",
      "1300:\tlearn: 0.2285569\ttest: 0.2595595\tbest: 0.2595595 (1300)\ttotal: 25s\tremaining: 3.83s\n",
      "1400:\tlearn: 0.2268882\ttest: 0.2584362\tbest: 0.2584362 (1400)\ttotal: 26.7s\tremaining: 1.89s\n",
      "1499:\tlearn: 0.2253606\ttest: 0.2573988\tbest: 0.2573988 (1499)\ttotal: 28.5s\tremaining: 0us\n",
      "bestTest = 0.2573987793\n",
      "bestIteration = 1499\n",
      ">>> ëª¨ë¸ ë°˜í™˜ ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "model = run_model_Cat_boost_comparison(data_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca53f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      ">>> [í‰ê°€] ëª¨ë¸ ìƒì„¸ ì„±ì í‘œ ì¶œë ¥\n",
      "============================================================\n",
      "â˜… Macro F1: 0.5926 / Acc: 0.8975\n",
      "------------------------------------------------------------\n",
      ">>> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.25      0.66      0.37        32\n",
      "           B       1.00      0.20      0.33         5\n",
      "           C       0.74      0.59      0.65      4253\n",
      "           D       0.70      0.62      0.66     11642\n",
      "           E       0.94      0.97      0.95     64068\n",
      "\n",
      "    accuracy                           0.90     80000\n",
      "   macro avg       0.73      0.61      0.59     80000\n",
      "weighted avg       0.89      0.90      0.89     80000\n",
      "\n",
      "------------------------------------------------------------\n",
      ">>> Confusion Matrix:\n",
      "\n",
      "[[   21     0    11     0     0]\n",
      " [    1     1     3     0     0]\n",
      " [   52     0  2508  1264   429]\n",
      " [    6     0   716  7220  3700]\n",
      " [    3     0   171  1845 62049]]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "# í•™ìŠµëœ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ê²€ì¦ ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€í•¨\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "val_pred = model.predict(data_pack[\"X_val\"]).flatten()\n",
    "\n",
    "# ì ìˆ˜ ê³„ì‚°\n",
    "f1 = f1_score(data_pack[\"y_val\"], val_pred, average='macro')\n",
    "acc = accuracy_score(data_pack[\"y_val\"], val_pred)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"Macro F1: {f1:.4f}, Accuracy: {acc:.4f}\")\n",
    "print(\"-\" * 50)\n",
    "print(\"ë¶„ë¥˜ ë¦¬í¬íŠ¸:\\n\")\n",
    "print(classification_report(data_pack[\"y_val\"], val_pred, target_names=data_pack[\"le_y\"].classes_))\n",
    "print(\"-\" * 50)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(data_pack[\"y_val\"], val_pred))\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
